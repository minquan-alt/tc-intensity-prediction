{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ehUHXdW34gT",
        "outputId": "f3d9ff86-7cb4-42b1-cbf9-299c3f567a17"
      },
      "outputs": [],
      "source": [
        "%config InteractiveShell.ast_node_interactivity = 'all'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fFoDXRLl3apE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x264d116f9b0>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gc\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchinfo import summary\n",
        "\n",
        "from layer.kan_layer import KANLinear, NewGELU\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wOWAQoGDiAqu"
      },
      "outputs": [],
      "source": [
        "def get_raw_data(raw_data_dict):\n",
        "  raw_data = {}\n",
        "  for dict_ in raw_data_dict.values():\n",
        "    raw_data.update(dict_)\n",
        "  return raw_data\n",
        "def load_and_process_data(data_path, train_years, val_years, test_years):\n",
        "  raw_train_data_dict = {}\n",
        "  raw_val_data_dict = {}\n",
        "  raw_test_data_dict = {}\n",
        "  for filename in os.listdir(data_path):\n",
        "    if filename.endswith('.pkl'):\n",
        "      year = int(filename[11:15])\n",
        "      if year not in train_years and year not in val_years and year not in test_years:\n",
        "        continue\n",
        "      with open(os.path.join(data_path, filename), 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "        if year in train_years:\n",
        "          raw_train_data_dict[filename] = data\n",
        "        elif year in val_years:\n",
        "          raw_val_data_dict[filename] = data\n",
        "        elif year in test_years:\n",
        "          raw_test_data_dict[filename] = data\n",
        "        else:\n",
        "          raise ValueError(f\"Invalid year: {year}\")\n",
        "\n",
        "  raw_train_data_dict = dict(sorted(raw_train_data_dict.items()))\n",
        "  raw_val_data_dict = dict(sorted(raw_val_data_dict.items()))\n",
        "  raw_test_data_dict = dict(sorted(raw_test_data_dict.items()))\n",
        "\n",
        "  raw_train_data = get_raw_data(raw_train_data_dict)\n",
        "  raw_val_data = get_raw_data(raw_val_data_dict)\n",
        "  raw_test_data = get_raw_data(raw_test_data_dict)\n",
        "  return raw_train_data, raw_val_data, raw_test_data\n",
        "\n",
        "def prepare_data(storm_data, sequence_length, n_ahead, dtype=np.float32):\n",
        "  total_sequence = 0\n",
        "  center_grid = 15\n",
        "  for sid, storm_records in storm_data.items():\n",
        "    if len(storm_records) < sequence_length + n_ahead:\n",
        "      continue\n",
        "    total_sequence += len(storm_records) - sequence_length - n_ahead + 1\n",
        "\n",
        "  first_key = next(iter(storm_data.keys()))\n",
        "\n",
        "  cma_len = len(storm_data[first_key][0]['targets'])\n",
        "  era5_single_len = storm_data[first_key][0]['features']['single'].shape[0]\n",
        "  era5_multi_len = storm_data[first_key][0]['features']['multi'][1:4].shape[0] * storm_data[first_key][0]['features']['multi'].shape[1]\n",
        "  features_len = cma_len + era5_single_len + era5_multi_len\n",
        "  input_shape = (total_sequence, sequence_length, features_len)\n",
        "  output_shape = (total_sequence, n_ahead)\n",
        "\n",
        "  X_sequences = np.empty(input_shape, dtype=dtype)\n",
        "  y_sequences = np.empty(output_shape, dtype=dtype)\n",
        "  sequence_metadata = [None] * total_sequence\n",
        "\n",
        "  valid_storms = 0\n",
        "  idx = 0\n",
        "\n",
        "  for sid, storm_records in storm_data.items():\n",
        "    if len(storm_records) < sequence_length + n_ahead:\n",
        "      continue\n",
        "\n",
        "    valid_storms += 1\n",
        "    L = len(storm_records) - sequence_length - n_ahead + 1\n",
        "\n",
        "    for i in range(L):\n",
        "      for j in range(sequence_length):\n",
        "        target = storm_records[i + j]['targets']\n",
        "        cma_features = dtype([target['center_lat'],target['center_lon'],target['vmax'],target['pmin']])\n",
        "\n",
        "        era5_features = []\n",
        "        single_era5_features = storm_records[i + j]['features']['single']\n",
        "        multi_era5_features = storm_records[i + j]['features']['multi'][1:4, :, :, :]\n",
        "\n",
        "        for m in range(single_era5_features.shape[0]):\n",
        "          era5_features.append(single_era5_features[m, center_grid, center_grid])\n",
        "        for m in range(multi_era5_features.shape[0]):\n",
        "          for n in range(multi_era5_features.shape[1]):\n",
        "            era5_features.append(multi_era5_features[m, n, center_grid, center_grid])\n",
        "\n",
        "        era5_features = dtype(era5_features)\n",
        "\n",
        "        X_sequences[idx, j, :4] = cma_features\n",
        "        X_sequences[idx, j, 4:] = era5_features\n",
        "\n",
        "      for j in range(n_ahead):\n",
        "        target = storm_records[i + sequence_length + j]['targets']\n",
        "        y_sequences[idx, j] = dtype(target['vmax'])\n",
        "\n",
        "      sequence_metadata[idx] = {\n",
        "        'storm_id': sid,\n",
        "        'input_times': [storm_records[i + j]['time'] for j in range(sequence_length)],\n",
        "        'target_time': [storm_records[i + sequence_length + j]['time'] for j in range(n_ahead)]\n",
        "      }\n",
        "\n",
        "      idx += 1\n",
        "  if idx < total_sequence:\n",
        "    X_sequences = X_sequences[:idx]\n",
        "    y_sequences = y_sequences[:idx]\n",
        "    sequence_metadata = sequence_metadata[:idx]\n",
        "\n",
        "  metadata = {\n",
        "    'n_sequences': idx,\n",
        "    'sequence_length': sequence_length,\n",
        "    'n_storms': valid_storms,\n",
        "    'sequence_metadata': sequence_metadata,\n",
        "  }\n",
        "\n",
        "  gc.collect()\n",
        "  return (X_sequences, y_sequences, metadata)\n",
        "\n",
        "class StormDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        if not torch.is_tensor(X):\n",
        "            self.X = torch.from_numpy(X).float()\n",
        "        else:\n",
        "            self.X = X.float()\n",
        "\n",
        "        if not torch.is_tensor(y):\n",
        "            self.y = torch.from_numpy(y).float()\n",
        "        else:\n",
        "            self.y = y.float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yyTRS6gQU4x",
        "outputId": "130c8734-a062-474a-a8a2-b55e5d3bdf75"
      },
      "outputs": [],
      "source": [
        "class RNN_KAN_Cell(nn.Module):\n",
        "    \"\"\"\n",
        "        x: (batch, in_features)\n",
        "        h0: (batch, hidden_features)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, hidden_features, activation=nn.Tanh):\n",
        "        super(RNN_KAN_Cell, self).__init__()\n",
        "        assert in_features[-1] == hidden_features, f\"in_features[-1]={in_features[-1]} phải bằng hidden_features={hidden_features}\"\n",
        "        self.in_features = in_features\n",
        "        self.hidden_features = hidden_features\n",
        "        self.activation = activation()\n",
        "        self.i2h = KANLinear(in_features[0], in_features[1])\n",
        "        self.h2h = nn.Linear(hidden_features, hidden_features) # W_hh @ h + b_h\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        return self.activation(self.i2h(x) + self.h2h(h))\n",
        "\n",
        "class RNN_KAN(nn.Module):\n",
        "    \"\"\"\n",
        "        x: (batch, seq_len, in_features)\n",
        "        h0: (batch, hidden_features)\n",
        "        in_features: list - last idx must equal to hidden_features\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, hidden_features, output_features, n_ahead, activation=nn.Tanh):\n",
        "        super(RNN_KAN, self).__init__()\n",
        "        self.hidden_features = hidden_features\n",
        "        self.in_features = in_features\n",
        "        self.RNN_KAN_Cell = RNN_KAN_Cell(in_features, hidden_features, activation)\n",
        "        self.fc_out = nn.Linear(hidden_features, output_features)\n",
        "\n",
        "        self.n_ahead = n_ahead\n",
        "        self.output_features = output_features\n",
        "    def forward(self, x, h0=None):\n",
        "        batch, Tx, _ = x.size()\n",
        "        Ty = self.n_ahead\n",
        "        h = torch.zeros(batch, Tx + Ty, self.hidden_features, device=x.device)\n",
        "        y_pred = torch.zeros(batch, Ty, self.output_features, device=x.device)\n",
        "        if h0 is None:\n",
        "            h0 = torch.zeros(batch, self.hidden_features, device=x.device)\n",
        "\n",
        "        h_t = h0\n",
        "        for t in range(Tx):\n",
        "            h_t = self.RNN_KAN_Cell(x[:, t, :], h_t)\n",
        "            h[:, t, :] = h_t\n",
        "        for t in range(Ty):\n",
        "            h_t = self.RNN_KAN_Cell(torch.zeros(batch, self.in_features[0], device=x.device), h_t)\n",
        "            h[:, Tx + t, :] = h_t\n",
        "            y_t = self.fc_out(h_t)\n",
        "            y_pred[:, t, :] = y_t\n",
        "        return y_pred.squeeze(dim=2), h\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Esu0VLYhmbH-"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader, scaler_y, device):\n",
        "  mae_loss = nn.L1Loss()\n",
        "  running_loss = 0.0\n",
        "  total_samples = 0\n",
        "\n",
        "  model.eval()\n",
        "  for batch_x, batch_y in test_loader:\n",
        "    batch_x = batch_x.float().to(device)\n",
        "    batch_y = batch_y.float().to(device)\n",
        "    b = batch_x.size(0)\n",
        "    total_samples += b\n",
        "\n",
        "    y_pred, _ = model(batch_x)\n",
        "\n",
        "    y_true_pred = scaler_y.inverse_transform(y_pred.cpu().detach().numpy())\n",
        "    y_true_true = scaler_y.inverse_transform(batch_y.cpu().detach().numpy())\n",
        "\n",
        "    test_mse_loss = mae_loss(torch.from_numpy(y_true_pred), torch.from_numpy(y_true_true))\n",
        "    running_loss += test_mse_loss.item() * b\n",
        "\n",
        "  test_mae_loss = running_loss / len(test_loader.dataset)\n",
        "\n",
        "  return test_mae_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "r7Tsuiipkxur"
      },
      "outputs": [],
      "source": [
        "def train_val(model, criterion, optimizer, train_loader, val_loader, device, batch_size=128, epochs=10):\n",
        "  train_loss_per_epoch = []\n",
        "  val_loss_per_epoch = []\n",
        "\n",
        "  total_time = time.time()\n",
        "  for epoch in range(epochs):\n",
        "      model.train()\n",
        "      running_loss = 0.0\n",
        "      total_samples = 0\n",
        "      for i, (batch_x, batch_y) in enumerate(train_loader):\n",
        "          batch_x = batch_x.float().to(device) # (128, 5, 20)\n",
        "          batch_y = batch_y.float().to(device) # (128, 4)\n",
        "\n",
        "          if epoch == 0 and i == 0:\n",
        "              print(f\"batch_x shape: {batch_x.size()}\")\n",
        "              print(f\"batch_y shape: {batch_y.size()}\")\n",
        "\n",
        "          b = batch_x.size(0)\n",
        "          total_samples += b\n",
        "          h0 = None\n",
        "\n",
        "          # pred\n",
        "          y_pred, _ = model(batch_x, h0)\n",
        "\n",
        "          # backprop\n",
        "          loss = criterion(y_pred, batch_y)\n",
        "          running_loss += loss.item() * b\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "      train_epoch_loss = running_loss / total_samples\n",
        "      train_loss_per_epoch.append(train_epoch_loss)\n",
        "\n",
        "\n",
        "      model.eval()\n",
        "      running_loss = 0.0\n",
        "      total_samples = 0\n",
        "      for batch_x, batch_y in val_loader:\n",
        "          batch_x = batch_x.float().to(device) # (128, 5, 20)\n",
        "          batch_y = batch_y.float().to(device) # (128, 4, 1)\n",
        "          b = batch_x.size(0)\n",
        "          total_samples += b\n",
        "          h0 = None\n",
        "\n",
        "          # pred\n",
        "          y_pred, _ = model(batch_x)\n",
        "          loss = criterion(y_pred, batch_y)\n",
        "          running_loss += loss.item() * b\n",
        "\n",
        "      val_epoch_loss = running_loss / total_samples\n",
        "      val_loss_per_epoch.append(val_epoch_loss)\n",
        "\n",
        "      print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_epoch_loss:.4f}, Val Loss: {val_epoch_loss:.4f}\")\n",
        "\n",
        "  total_time = time.time() - total_time\n",
        "\n",
        "  # plt.plot(train_loss_per_epoch)\n",
        "  # plt.plot(val_loss_per_epoch)\n",
        "  # plt.legend(['train', 'val'])\n",
        "  # plt.show()\n",
        "\n",
        "  return model, total_time, train_loss_per_epoch, val_loss_per_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYWizI-34G3g",
        "outputId": "cee95673-5728-4e3b-c6e5-87db590295b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "RNN_KAN                                  [128, 4]                  --\n",
              "├─RNN_KAN_Cell: 1-1                      [128, 100]                --\n",
              "│    └─KANLinear: 2-1                    [128, 100]                20,000\n",
              "│    │    └─SiLU: 3-1                    [128, 20]                 --\n",
              "│    │    └─SiLU: 3-2                    [128, 20]                 --\n",
              "│    └─Linear: 2-2                       [128, 100]                10,100\n",
              "│    └─Tanh: 2-3                         [128, 100]                --\n",
              "├─RNN_KAN_Cell: 1-2                      [128, 100]                (recursive)\n",
              "│    └─KANLinear: 2-4                    [128, 100]                (recursive)\n",
              "│    │    └─SiLU: 3-3                    [128, 20]                 --\n",
              "│    │    └─SiLU: 3-4                    [128, 20]                 --\n",
              "│    └─Linear: 2-5                       [128, 100]                (recursive)\n",
              "│    └─Tanh: 2-6                         [128, 100]                --\n",
              "├─RNN_KAN_Cell: 1-3                      [128, 100]                (recursive)\n",
              "│    └─KANLinear: 2-7                    [128, 100]                (recursive)\n",
              "│    │    └─SiLU: 3-5                    [128, 20]                 --\n",
              "│    │    └─SiLU: 3-6                    [128, 20]                 --\n",
              "│    └─Linear: 2-8                       [128, 100]                (recursive)\n",
              "│    └─Tanh: 2-9                         [128, 100]                --\n",
              "├─RNN_KAN_Cell: 1-4                      [128, 100]                (recursive)\n",
              "│    └─KANLinear: 2-10                   [128, 100]                (recursive)\n",
              "│    │    └─SiLU: 3-7                    [128, 20]                 --\n",
              "│    │    └─SiLU: 3-8                    [128, 20]                 --\n",
              "│    └─Linear: 2-11                      [128, 100]                (recursive)\n",
              "│    └─Tanh: 2-12                        [128, 100]                --\n",
              "├─RNN_KAN_Cell: 1-5                      [128, 100]                (recursive)\n",
              "│    └─KANLinear: 2-13                   [128, 100]                (recursive)\n",
              "│    │    └─SiLU: 3-9                    [128, 20]                 --\n",
              "│    │    └─SiLU: 3-10                   [128, 20]                 --\n",
              "│    └─Linear: 2-14                      [128, 100]                (recursive)\n",
              "│    └─Tanh: 2-15                        [128, 100]                --\n",
              "├─RNN_KAN_Cell: 1-6                      [128, 100]                (recursive)\n",
              "│    └─KANLinear: 2-16                   [128, 100]                (recursive)\n",
              "│    │    └─SiLU: 3-11                   [128, 20]                 --\n",
              "│    │    └─SiLU: 3-12                   [128, 20]                 --\n",
              "│    └─Linear: 2-17                      [128, 100]                (recursive)\n",
              "│    └─Tanh: 2-18                        [128, 100]                --\n",
              "├─Linear: 1-7                            [128, 1]                  101\n",
              "├─RNN_KAN_Cell: 1-8                      [128, 100]                (recursive)\n",
              "│    └─KANLinear: 2-19                   [128, 100]                (recursive)\n",
              "│    │    └─SiLU: 3-13                   [128, 20]                 --\n",
              "│    │    └─SiLU: 3-14                   [128, 20]                 --\n",
              "│    └─Linear: 2-20                      [128, 100]                (recursive)\n",
              "│    └─Tanh: 2-21                        [128, 100]                --\n",
              "├─Linear: 1-9                            [128, 1]                  (recursive)\n",
              "├─RNN_KAN_Cell: 1-10                     [128, 100]                (recursive)\n",
              "│    └─KANLinear: 2-22                   [128, 100]                (recursive)\n",
              "│    │    └─SiLU: 3-15                   [128, 20]                 --\n",
              "│    │    └─SiLU: 3-16                   [128, 20]                 --\n",
              "│    └─Linear: 2-23                      [128, 100]                (recursive)\n",
              "│    └─Tanh: 2-24                        [128, 100]                --\n",
              "├─Linear: 1-11                           [128, 1]                  (recursive)\n",
              "├─RNN_KAN_Cell: 1-12                     [128, 100]                (recursive)\n",
              "│    └─KANLinear: 2-25                   [128, 100]                (recursive)\n",
              "│    │    └─SiLU: 3-17                   [128, 20]                 --\n",
              "│    │    └─SiLU: 3-18                   [128, 20]                 --\n",
              "│    └─Linear: 2-26                      [128, 100]                (recursive)\n",
              "│    └─Tanh: 2-27                        [128, 100]                --\n",
              "├─Linear: 1-13                           [128, 1]                  (recursive)\n",
              "==========================================================================================\n",
              "Total params: 30,201\n",
              "Trainable params: 30,201\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 11.69\n",
              "==========================================================================================\n",
              "Input size (MB): 0.05\n",
              "Forward/backward pass size (MB): 0.93\n",
              "Params size (MB): 0.04\n",
              "Estimated Total Size (MB): 1.02\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "in_features = (20, 100)\n",
        "hidden_features = 100\n",
        "output_features = 1\n",
        "seq_len = 5\n",
        "n_ahead = 4\n",
        "batch_size = 128\n",
        "\n",
        "model = RNN_KAN(in_features, hidden_features, output_features, n_ahead)\n",
        "\n",
        "summary(model, (batch_size, seq_len, in_features[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_path = 'data/cma_era5'\n",
        "raw_train_data, raw_val_data, raw_test_data = load_and_process_data(data_path=data_path, train_years=list(range(1980, 2017)), val_years=[2017, 2018, 2019], test_years=[2020, 2021, 2022])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6rNY5yXgjjqN",
        "outputId": "4afb7b31-136d-4053-98c9-628e9abcddc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using NVIDIA GeForce RTX 4060 Ti for device\n",
            "================== TRAINING n_ahead = 1 ==================\n",
            "X_shape: (25864, 5, 20)\n",
            "y_shape: (25864, 1)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 1])\n",
            "Epoch 1/10, Train Loss: 0.0935, Val Loss: 0.0399\n",
            "Epoch 2/10, Train Loss: 0.0412, Val Loss: 0.0343\n",
            "Epoch 3/10, Train Loss: 0.0394, Val Loss: 0.0373\n",
            "Epoch 4/10, Train Loss: 0.0384, Val Loss: 0.0359\n",
            "Epoch 5/10, Train Loss: 0.0384, Val Loss: 0.0334\n",
            "Epoch 6/10, Train Loss: 0.0372, Val Loss: 0.0313\n",
            "Epoch 7/10, Train Loss: 0.0370, Val Loss: 0.0344\n",
            "Epoch 8/10, Train Loss: 0.0362, Val Loss: 0.0329\n",
            "Epoch 9/10, Train Loss: 0.0364, Val Loss: 0.0318\n",
            "Epoch 10/10, Train Loss: 0.0364, Val Loss: 0.0302\n",
            "================== TRAINING n_ahead = 2 ==================\n",
            "X_shape: (24788, 5, 20)\n",
            "y_shape: (24788, 2)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 2])\n",
            "Epoch 1/10, Train Loss: 0.1500, Val Loss: 0.0837\n",
            "Epoch 2/10, Train Loss: 0.0838, Val Loss: 0.0754\n",
            "Epoch 3/10, Train Loss: 0.0783, Val Loss: 0.0714\n",
            "Epoch 4/10, Train Loss: 0.0748, Val Loss: 0.0694\n",
            "Epoch 5/10, Train Loss: 0.0725, Val Loss: 0.0662\n",
            "Epoch 6/10, Train Loss: 0.0695, Val Loss: 0.0633\n",
            "Epoch 7/10, Train Loss: 0.0686, Val Loss: 0.0663\n",
            "Epoch 8/10, Train Loss: 0.0660, Val Loss: 0.0622\n",
            "Epoch 9/10, Train Loss: 0.0637, Val Loss: 0.0652\n",
            "Epoch 10/10, Train Loss: 0.0629, Val Loss: 0.0598\n",
            "================== TRAINING n_ahead = 3 ==================\n",
            "X_shape: (23716, 5, 20)\n",
            "y_shape: (23716, 3)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 3])\n",
            "Epoch 1/10, Train Loss: 0.2190, Val Loss: 0.1517\n",
            "Epoch 2/10, Train Loss: 0.1279, Val Loss: 0.1276\n",
            "Epoch 3/10, Train Loss: 0.1195, Val Loss: 0.1332\n",
            "Epoch 4/10, Train Loss: 0.1103, Val Loss: 0.1146\n",
            "Epoch 5/10, Train Loss: 0.1062, Val Loss: 0.0986\n",
            "Epoch 6/10, Train Loss: 0.1005, Val Loss: 0.0965\n",
            "Epoch 7/10, Train Loss: 0.0962, Val Loss: 0.0894\n",
            "Epoch 8/10, Train Loss: 0.0914, Val Loss: 0.0900\n",
            "Epoch 9/10, Train Loss: 0.0911, Val Loss: 0.0962\n",
            "Epoch 10/10, Train Loss: 0.0881, Val Loss: 0.0880\n",
            "================== TRAINING n_ahead = 4 ==================\n",
            "X_shape: (22648, 5, 20)\n",
            "y_shape: (22648, 4)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 4])\n",
            "Epoch 1/10, Train Loss: 0.2844, Val Loss: 0.2190\n",
            "Epoch 2/10, Train Loss: 0.1848, Val Loss: 0.1716\n",
            "Epoch 3/10, Train Loss: 0.1515, Val Loss: 0.1490\n",
            "Epoch 4/10, Train Loss: 0.1380, Val Loss: 0.1332\n",
            "Epoch 5/10, Train Loss: 0.1275, Val Loss: 0.1246\n",
            "Epoch 6/10, Train Loss: 0.1228, Val Loss: 0.1295\n",
            "Epoch 7/10, Train Loss: 0.1215, Val Loss: 0.1279\n",
            "Epoch 8/10, Train Loss: 0.1138, Val Loss: 0.1246\n",
            "Epoch 9/10, Train Loss: 0.1139, Val Loss: 0.1206\n",
            "Epoch 10/10, Train Loss: 0.1116, Val Loss: 0.1219\n",
            "================== TRAINING n_ahead = 5 ==================\n",
            "X_shape: (21595, 5, 20)\n",
            "y_shape: (21595, 5)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 5])\n",
            "Epoch 1/10, Train Loss: 0.3326, Val Loss: 0.2624\n",
            "Epoch 2/10, Train Loss: 0.2467, Val Loss: 0.2383\n",
            "Epoch 3/10, Train Loss: 0.2250, Val Loss: 0.2137\n",
            "Epoch 4/10, Train Loss: 0.1989, Val Loss: 0.1902\n",
            "Epoch 5/10, Train Loss: 0.1768, Val Loss: 0.1723\n",
            "Epoch 6/10, Train Loss: 0.1600, Val Loss: 0.1734\n",
            "Epoch 7/10, Train Loss: 0.1560, Val Loss: 0.1638\n",
            "Epoch 8/10, Train Loss: 0.1481, Val Loss: 0.1498\n",
            "Epoch 9/10, Train Loss: 0.1434, Val Loss: 0.1491\n",
            "Epoch 10/10, Train Loss: 0.1390, Val Loss: 0.1459\n",
            "================== TRAINING n_ahead = 6 ==================\n",
            "X_shape: (20565, 5, 20)\n",
            "y_shape: (20565, 6)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 6])\n",
            "Epoch 1/10, Train Loss: 0.3761, Val Loss: 0.2982\n",
            "Epoch 2/10, Train Loss: 0.2782, Val Loss: 0.2688\n",
            "Epoch 3/10, Train Loss: 0.2574, Val Loss: 0.2567\n",
            "Epoch 4/10, Train Loss: 0.2378, Val Loss: 0.2283\n",
            "Epoch 5/10, Train Loss: 0.2198, Val Loss: 0.2228\n",
            "Epoch 6/10, Train Loss: 0.1997, Val Loss: 0.2111\n",
            "Epoch 7/10, Train Loss: 0.1875, Val Loss: 0.1902\n",
            "Epoch 8/10, Train Loss: 0.1787, Val Loss: 0.2231\n",
            "Epoch 9/10, Train Loss: 0.1707, Val Loss: 0.1846\n",
            "Epoch 10/10, Train Loss: 0.1696, Val Loss: 0.1920\n",
            "================== TRAINING n_ahead = 7 ==================\n",
            "X_shape: (19556, 5, 20)\n",
            "y_shape: (19556, 7)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 7])\n",
            "Epoch 1/10, Train Loss: 0.4278, Val Loss: 0.3576\n",
            "Epoch 2/10, Train Loss: 0.3180, Val Loss: 0.3514\n",
            "Epoch 3/10, Train Loss: 0.3037, Val Loss: 0.2950\n",
            "Epoch 4/10, Train Loss: 0.2818, Val Loss: 0.2765\n",
            "Epoch 5/10, Train Loss: 0.2657, Val Loss: 0.2873\n",
            "Epoch 6/10, Train Loss: 0.2465, Val Loss: 0.2618\n",
            "Epoch 7/10, Train Loss: 0.2298, Val Loss: 0.2332\n",
            "Epoch 8/10, Train Loss: 0.2121, Val Loss: 0.2212\n",
            "Epoch 9/10, Train Loss: 0.2019, Val Loss: 0.2329\n",
            "Epoch 10/10, Train Loss: 0.1989, Val Loss: 0.2089\n",
            "================== TRAINING n_ahead = 8 ==================\n",
            "X_shape: (18567, 5, 20)\n",
            "y_shape: (18567, 8)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 8])\n",
            "Epoch 1/10, Train Loss: 0.4543, Val Loss: 0.3740\n",
            "Epoch 2/10, Train Loss: 0.3451, Val Loss: 0.3890\n",
            "Epoch 3/10, Train Loss: 0.3286, Val Loss: 0.3816\n",
            "Epoch 4/10, Train Loss: 0.3101, Val Loss: 0.3469\n",
            "Epoch 5/10, Train Loss: 0.2914, Val Loss: 0.3045\n",
            "Epoch 6/10, Train Loss: 0.2723, Val Loss: 0.3549\n",
            "Epoch 7/10, Train Loss: 0.2570, Val Loss: 0.2724\n",
            "Epoch 8/10, Train Loss: 0.2397, Val Loss: 0.2836\n",
            "Epoch 9/10, Train Loss: 0.2335, Val Loss: 0.2424\n",
            "Epoch 10/10, Train Loss: 0.2226, Val Loss: 0.2368\n",
            "================== TRAINING n_ahead = 9 ==================\n",
            "X_shape: (17598, 5, 20)\n",
            "y_shape: (17598, 9)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 9])\n",
            "Epoch 1/10, Train Loss: 0.4991, Val Loss: 0.4127\n",
            "Epoch 2/10, Train Loss: 0.3751, Val Loss: 0.4162\n",
            "Epoch 3/10, Train Loss: 0.3578, Val Loss: 0.3797\n",
            "Epoch 4/10, Train Loss: 0.3421, Val Loss: 0.3707\n",
            "Epoch 5/10, Train Loss: 0.3372, Val Loss: 0.3803\n",
            "Epoch 6/10, Train Loss: 0.3272, Val Loss: 0.3479\n",
            "Epoch 7/10, Train Loss: 0.3143, Val Loss: 0.3538\n",
            "Epoch 8/10, Train Loss: 0.3028, Val Loss: 0.3274\n",
            "Epoch 9/10, Train Loss: 0.2897, Val Loss: 0.3023\n",
            "Epoch 10/10, Train Loss: 0.2728, Val Loss: 0.3046\n",
            "================== TRAINING n_ahead = 10 ==================\n",
            "X_shape: (16663, 5, 20)\n",
            "y_shape: (16663, 10)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 10])\n",
            "Epoch 1/10, Train Loss: 0.5337, Val Loss: 0.4654\n",
            "Epoch 2/10, Train Loss: 0.4016, Val Loss: 0.4110\n",
            "Epoch 3/10, Train Loss: 0.3801, Val Loss: 0.4055\n",
            "Epoch 4/10, Train Loss: 0.3646, Val Loss: 0.4200\n",
            "Epoch 5/10, Train Loss: 0.3533, Val Loss: 0.3827\n",
            "Epoch 6/10, Train Loss: 0.3439, Val Loss: 0.3737\n",
            "Epoch 7/10, Train Loss: 0.3246, Val Loss: 0.3734\n",
            "Epoch 8/10, Train Loss: 0.3143, Val Loss: 0.3581\n",
            "Epoch 9/10, Train Loss: 0.2962, Val Loss: 0.3498\n",
            "Epoch 10/10, Train Loss: 0.2882, Val Loss: 0.3202\n",
            "================== TRAINING n_ahead = 11 ==================\n",
            "X_shape: (15757, 5, 20)\n",
            "y_shape: (15757, 11)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 11])\n",
            "Epoch 1/10, Train Loss: 0.5539, Val Loss: 0.5041\n",
            "Epoch 2/10, Train Loss: 0.4310, Val Loss: 0.4595\n",
            "Epoch 3/10, Train Loss: 0.4051, Val Loss: 0.4244\n",
            "Epoch 4/10, Train Loss: 0.3932, Val Loss: 0.4651\n",
            "Epoch 5/10, Train Loss: 0.3887, Val Loss: 0.4343\n",
            "Epoch 6/10, Train Loss: 0.3761, Val Loss: 0.4709\n",
            "Epoch 7/10, Train Loss: 0.3577, Val Loss: 0.4340\n",
            "Epoch 8/10, Train Loss: 0.3377, Val Loss: 0.4465\n",
            "Epoch 9/10, Train Loss: 0.3265, Val Loss: 0.3763\n",
            "Epoch 10/10, Train Loss: 0.3165, Val Loss: 0.3569\n",
            "================== TRAINING n_ahead = 12 ==================\n",
            "X_shape: (14881, 5, 20)\n",
            "y_shape: (14881, 12)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 12])\n",
            "Epoch 1/10, Train Loss: 0.5922, Val Loss: 0.5153\n",
            "Epoch 2/10, Train Loss: 0.4454, Val Loss: 0.4760\n",
            "Epoch 3/10, Train Loss: 0.4238, Val Loss: 0.4822\n",
            "Epoch 4/10, Train Loss: 0.4110, Val Loss: 0.4750\n",
            "Epoch 5/10, Train Loss: 0.4036, Val Loss: 0.4768\n",
            "Epoch 6/10, Train Loss: 0.3914, Val Loss: 0.4904\n",
            "Epoch 7/10, Train Loss: 0.3822, Val Loss: 0.4458\n",
            "Epoch 8/10, Train Loss: 0.3771, Val Loss: 0.4602\n",
            "Epoch 9/10, Train Loss: 0.3623, Val Loss: 0.4274\n",
            "Epoch 10/10, Train Loss: 0.3455, Val Loss: 0.4180\n"
          ]
        }
      ],
      "source": [
        "#====================== Train model ======================#\n",
        "# config\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {torch.cuda.get_device_name(0)} for device\")\n",
        "\n",
        "# hyperparams\n",
        "in_features = (20, 100)\n",
        "hidden_features = 100\n",
        "output_features = 1\n",
        "seq_len = 5\n",
        "n_aheads = list(range(1, 13))\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "lr = 1e-3\n",
        "\n",
        "results = {}\n",
        "\n",
        "for n_ahead in n_aheads:\n",
        "  print(f\"================== TRAINING n_ahead = {n_ahead} ==================\")\n",
        "  X_train, y_train, metadata_train = prepare_data(raw_train_data, sequence_length = 5, n_ahead = n_ahead)\n",
        "  X_val, y_val, metadata_val = prepare_data(raw_val_data, sequence_length = 5, n_ahead = n_ahead)\n",
        "  X_test, y_test, metadata_test = prepare_data(raw_test_data, sequence_length = 5, n_ahead = n_ahead)\n",
        "\n",
        "  print(f\"X_shape: {X_train.shape}\")\n",
        "  print(f\"y_shape: {y_train.shape}\")\n",
        "\n",
        "  raw_test_data_2020 = {k: v for k, v in raw_test_data.items() if int(k[-4:]) == 2020}\n",
        "  raw_test_data_2021 = {k: v for k, v in raw_test_data.items() if int(k[-4:]) == 2021}\n",
        "  raw_test_data_2022 = {k: v for k, v in raw_test_data.items() if int(k[-4:]) == 2022}\n",
        "\n",
        "  X_test_2020, y_test_2020, metadata_test_2020 = prepare_data(raw_test_data_2020, sequence_length = 5, n_ahead = n_ahead)\n",
        "  X_test_2021, y_test_2021, metadata_test_2021 = prepare_data(raw_test_data_2021, sequence_length = 5, n_ahead = n_ahead)\n",
        "  X_test_2022, y_test_2022, metadata_test_2022 = prepare_data(raw_test_data_2022, sequence_length = 5, n_ahead = n_ahead)\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  X_train_scaled = scaler_X.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
        "  X_val_scaled   = scaler_X.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)\n",
        "  X_test_scaled  = scaler_X.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
        "  X_test_2020_scaled = scaler_X.transform(X_test_2020.reshape(-1, X_test_2020.shape[-1])).reshape(X_test_2020.shape)\n",
        "  X_test_2021_scaled = scaler_X.transform(X_test_2021.reshape(-1, X_test_2021.shape[-1])).reshape(X_test_2021.shape)\n",
        "  X_test_2022_scaled = scaler_X.transform(X_test_2022.reshape(-1, X_test_2022.shape[-1])).reshape(X_test_2022.shape)\n",
        "\n",
        "  scaler_y = StandardScaler()\n",
        "  y_train_scaled = scaler_y.fit_transform(y_train)\n",
        "  y_val_scaled   = scaler_y.transform(y_val)\n",
        "  y_test_scaled  = scaler_y.transform(y_test)\n",
        "  y_test_2020_scaled = scaler_y.transform(y_test_2020)\n",
        "  y_test_2021_scaled = scaler_y.transform(y_test_2021)\n",
        "  y_test_2022_scaled = scaler_y.transform(y_test_2022)\n",
        "\n",
        "  train_dataset = StormDataset(X_train_scaled, y_train_scaled)\n",
        "  val_dataset = StormDataset(X_val_scaled, y_val_scaled)\n",
        "  test_dataset = StormDataset(X_test_scaled, y_test_scaled)\n",
        "  test_dataset_2020 = StormDataset(X_test_2020_scaled, y_test_2020_scaled)\n",
        "  test_dataset_2021 = StormDataset(X_test_2021_scaled, y_test_2021_scaled)\n",
        "  test_dataset_2022 = StormDataset(X_test_2022_scaled, y_test_2022_scaled)\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
        "  val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "  test_2020_loader = DataLoader(test_dataset_2020, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "  test_2021_loader = DataLoader(test_dataset_2021, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "  test_2022_loader = DataLoader(test_dataset_2022, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "  model = RNN_KAN(in_features, hidden_features, output_features, n_ahead)\n",
        "  model = model.to(device)\n",
        "  criterion = nn.MSELoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "  model, total_time, train_loss_per_epoch, val_loss_per_epoch = train_val(model, criterion, optimizer, train_loader, val_loader, device, batch_size, epochs)\n",
        "\n",
        "  test_mae = test(model, test_loader, scaler_y, device)\n",
        "  test_2020_mae = test(model, test_2020_loader, scaler_y, device)\n",
        "  test_2021_mae = test(model, test_2021_loader, scaler_y, device)\n",
        "  test_2022_mae = test(model, test_2022_loader, scaler_y, device)\n",
        "\n",
        "  results[n_ahead] = {\n",
        "      \"mae\": [test_mae, test_2020_mae, test_2021_mae, test_2022_mae],\n",
        "      \"time\": [total_time]\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6jVt9W4oUrZ",
        "outputId": "f9b454dd-3eb5-4955-de2a-baf94bde1cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction 6h: \n",
            "\t Total time: 13.64s\n",
            "\t Test MAE: 2.1584\n",
            "\t Test 2020 MAE: 1.6396\n",
            "\t Test 2021 MAE: 1.5002\n",
            "\t Test 2022 MAE: 3.5745\n",
            "Prediction 12h: \n",
            "\t Total time: 14.77s\n",
            "\t Test MAE: 3.2734\n",
            "\t Test 2020 MAE: 2.3647\n",
            "\t Test 2021 MAE: 2.2472\n",
            "\t Test 2022 MAE: 5.6135\n",
            "Prediction 18h: \n",
            "\t Total time: 16.61s\n",
            "\t Test MAE: 3.8540\n",
            "\t Test 2020 MAE: 2.7879\n",
            "\t Test 2021 MAE: 2.7134\n",
            "\t Test 2022 MAE: 6.5492\n",
            "Prediction 24h: \n",
            "\t Total time: 17.02s\n",
            "\t Test MAE: 4.1209\n",
            "\t Test 2020 MAE: 3.2074\n",
            "\t Test 2021 MAE: 2.9418\n",
            "\t Test 2022 MAE: 6.7463\n",
            "Prediction 30h: \n",
            "\t Total time: 26.89s\n",
            "\t Test MAE: 4.5103\n",
            "\t Test 2020 MAE: 3.4612\n",
            "\t Test 2021 MAE: 3.3348\n",
            "\t Test 2022 MAE: 7.3145\n",
            "Prediction 36h: \n",
            "\t Total time: 22.94s\n",
            "\t Test MAE: 5.2042\n",
            "\t Test 2020 MAE: 4.2179\n",
            "\t Test 2021 MAE: 3.9945\n",
            "\t Test 2022 MAE: 8.0309\n",
            "Prediction 42h: \n",
            "\t Total time: 29.66s\n",
            "\t Test MAE: 5.6628\n",
            "\t Test 2020 MAE: 4.2999\n",
            "\t Test 2021 MAE: 4.5120\n",
            "\t Test 2022 MAE: 8.8635\n",
            "Prediction 48h: \n",
            "\t Total time: 30.28s\n",
            "\t Test MAE: 5.8051\n",
            "\t Test 2020 MAE: 4.5698\n",
            "\t Test 2021 MAE: 4.6137\n",
            "\t Test 2022 MAE: 8.9775\n",
            "Prediction 54h: \n",
            "\t Total time: 20.21s\n",
            "\t Test MAE: 6.6761\n",
            "\t Test 2020 MAE: 5.6818\n",
            "\t Test 2021 MAE: 5.3482\n",
            "\t Test 2022 MAE: 9.8519\n",
            "Prediction 60h: \n",
            "\t Total time: 20.78s\n",
            "\t Test MAE: 6.5938\n",
            "\t Test 2020 MAE: 5.6425\n",
            "\t Test 2021 MAE: 5.4250\n",
            "\t Test 2022 MAE: 9.5082\n",
            "Prediction 66h: \n",
            "\t Total time: 20.52s\n",
            "\t Test MAE: 7.0419\n",
            "\t Test 2020 MAE: 6.1448\n",
            "\t Test 2021 MAE: 5.4886\n",
            "\t Test 2022 MAE: 10.5478\n",
            "Prediction 72h: \n",
            "\t Total time: 20.20s\n",
            "\t Test MAE: 7.5507\n",
            "\t Test 2020 MAE: 6.5920\n",
            "\t Test 2021 MAE: 5.9177\n",
            "\t Test 2022 MAE: 11.2878\n"
          ]
        }
      ],
      "source": [
        "for k,v in results.items():\n",
        "  print(f\"Prediction {k*6}h: \")\n",
        "  print(f\"\\t Total time: {v['time'][0]:.2f}s\")\n",
        "  print(f\"\\t Test MAE: {v['mae'][0]:.4f}\")\n",
        "  print(f\"\\t Test 2020 MAE: {v['mae'][1]:.4f}\")\n",
        "  print(f\"\\t Test 2021 MAE: {v['mae'][2]:.4f}\")\n",
        "  print(f\"\\t Test 2022 MAE: {v['mae'][3]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtOuTPkmpkm3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
