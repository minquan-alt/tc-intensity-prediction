{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ehUHXdW34gT",
        "outputId": "f3d9ff86-7cb4-42b1-cbf9-299c3f567a17"
      },
      "outputs": [],
      "source": [
        "%config InteractiveShell.ast_node_interactivity = 'all'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fFoDXRLl3apE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gc\n",
        "import pickle\n",
        "import wandb\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchinfo import summary\n",
        "\n",
        "from layer.kan_layer import KANLinear, NewGELU\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from utils.data_utils import StormDataset, prepare_data\n",
        "\n",
        "from utils.data_utils import prepare_data\n",
        "from utils.model_utils import train_val, test\n",
        "from utils.load_dataset import DataModule\n",
        "from model.rnn_kan_v1_1 import RNN_KAN\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYWizI-34G3g",
        "outputId": "cee95673-5728-4e3b-c6e5-87db590295b5"
      },
      "outputs": [],
      "source": [
        "# in_features = (20, 50, 100)\n",
        "# hidden_features = 100\n",
        "# output_features = 1\n",
        "# seq_len = 5\n",
        "# n_ahead = 4\n",
        "# batch_size = 128\n",
        "\n",
        "# model = RNN_KAN(in_features, hidden_features, output_features, n_ahead)\n",
        "\n",
        "# summary(model, (batch_size, seq_len, in_features[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_path = 'data/cma_era5'\n",
        "raw_train_data, raw_val_data, raw_test_data = load_and_process_data(data_path=data_path, train_years=list(range(1980, 2017)), val_years=[2017, 2018, 2019], test_years=[2020, 2021, 2022])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6rNY5yXgjjqN",
        "outputId": "4afb7b31-136d-4053-98c9-628e9abcddc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using NVIDIA GeForce RTX 4060 Ti for device\n",
            "================== TRAINING n_ahead = 1 ==================\n",
            "X_shape: (25864, 5, 20)\n",
            "y_shape: (25864, 1)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 1])\n",
            "Epoch 1/10, Train Loss: 0.1389, Val Loss: 0.0359\n",
            "Epoch 2/10, Train Loss: 0.0413, Val Loss: 0.0363\n",
            "Epoch 3/10, Train Loss: 0.0385, Val Loss: 0.0325\n",
            "Epoch 4/10, Train Loss: 0.0374, Val Loss: 0.0307\n",
            "Epoch 5/10, Train Loss: 0.0366, Val Loss: 0.0303\n",
            "Epoch 6/10, Train Loss: 0.0359, Val Loss: 0.0313\n",
            "Epoch 7/10, Train Loss: 0.0361, Val Loss: 0.0312\n",
            "Epoch 8/10, Train Loss: 0.0353, Val Loss: 0.0288\n",
            "Epoch 9/10, Train Loss: 0.0351, Val Loss: 0.0336\n",
            "Epoch 10/10, Train Loss: 0.0349, Val Loss: 0.0311\n",
            "================== TRAINING n_ahead = 2 ==================\n",
            "X_shape: (24788, 5, 20)\n",
            "y_shape: (24788, 2)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 2])\n",
            "Epoch 1/10, Train Loss: 0.2012, Val Loss: 0.0834\n",
            "Epoch 2/10, Train Loss: 0.0827, Val Loss: 0.0693\n",
            "Epoch 3/10, Train Loss: 0.0730, Val Loss: 0.0596\n",
            "Epoch 4/10, Train Loss: 0.0645, Val Loss: 0.0540\n",
            "Epoch 5/10, Train Loss: 0.0599, Val Loss: 0.0554\n",
            "Epoch 6/10, Train Loss: 0.0584, Val Loss: 0.0540\n",
            "Epoch 7/10, Train Loss: 0.0564, Val Loss: 0.0574\n",
            "Epoch 8/10, Train Loss: 0.0557, Val Loss: 0.0515\n",
            "Epoch 9/10, Train Loss: 0.0543, Val Loss: 0.0522\n",
            "Epoch 10/10, Train Loss: 0.0536, Val Loss: 0.0517\n",
            "================== TRAINING n_ahead = 3 ==================\n",
            "X_shape: (23716, 5, 20)\n",
            "y_shape: (23716, 3)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 3])\n",
            "Epoch 1/10, Train Loss: 0.2852, Val Loss: 0.1614\n",
            "Epoch 2/10, Train Loss: 0.1266, Val Loss: 0.1064\n",
            "Epoch 3/10, Train Loss: 0.1022, Val Loss: 0.0958\n",
            "Epoch 4/10, Train Loss: 0.0921, Val Loss: 0.0925\n",
            "Epoch 5/10, Train Loss: 0.0886, Val Loss: 0.0852\n",
            "Epoch 6/10, Train Loss: 0.0847, Val Loss: 0.0817\n",
            "Epoch 7/10, Train Loss: 0.0822, Val Loss: 0.0810\n",
            "Epoch 8/10, Train Loss: 0.0808, Val Loss: 0.0789\n",
            "Epoch 9/10, Train Loss: 0.0783, Val Loss: 0.0806\n",
            "Epoch 10/10, Train Loss: 0.0777, Val Loss: 0.0781\n",
            "================== TRAINING n_ahead = 4 ==================\n",
            "X_shape: (22648, 5, 20)\n",
            "y_shape: (22648, 4)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 4])\n",
            "Epoch 1/10, Train Loss: 0.3412, Val Loss: 0.2236\n",
            "Epoch 2/10, Train Loss: 0.1876, Val Loss: 0.1605\n",
            "Epoch 3/10, Train Loss: 0.1420, Val Loss: 0.1338\n",
            "Epoch 4/10, Train Loss: 0.1250, Val Loss: 0.1179\n",
            "Epoch 5/10, Train Loss: 0.1150, Val Loss: 0.1150\n",
            "Epoch 6/10, Train Loss: 0.1111, Val Loss: 0.1124\n",
            "Epoch 7/10, Train Loss: 0.1099, Val Loss: 0.1210\n",
            "Epoch 8/10, Train Loss: 0.1058, Val Loss: 0.1097\n",
            "Epoch 9/10, Train Loss: 0.1036, Val Loss: 0.1103\n",
            "Epoch 10/10, Train Loss: 0.1009, Val Loss: 0.1171\n",
            "================== TRAINING n_ahead = 5 ==================\n",
            "X_shape: (21595, 5, 20)\n",
            "y_shape: (21595, 5)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 5])\n",
            "Epoch 1/10, Train Loss: 0.3914, Val Loss: 0.2541\n",
            "Epoch 2/10, Train Loss: 0.2374, Val Loss: 0.2471\n",
            "Epoch 3/10, Train Loss: 0.1911, Val Loss: 0.1774\n",
            "Epoch 4/10, Train Loss: 0.1632, Val Loss: 0.1600\n",
            "Epoch 5/10, Train Loss: 0.1540, Val Loss: 0.1506\n",
            "Epoch 6/10, Train Loss: 0.1456, Val Loss: 0.1432\n",
            "Epoch 7/10, Train Loss: 0.1381, Val Loss: 0.1415\n",
            "Epoch 8/10, Train Loss: 0.1355, Val Loss: 0.1507\n",
            "Epoch 9/10, Train Loss: 0.1309, Val Loss: 0.1349\n",
            "Epoch 10/10, Train Loss: 0.1276, Val Loss: 0.1574\n",
            "================== TRAINING n_ahead = 6 ==================\n",
            "X_shape: (20565, 5, 20)\n",
            "y_shape: (20565, 6)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 6])\n",
            "Epoch 1/10, Train Loss: 0.4491, Val Loss: 0.2945\n",
            "Epoch 2/10, Train Loss: 0.2646, Val Loss: 0.2491\n",
            "Epoch 3/10, Train Loss: 0.2308, Val Loss: 0.2228\n",
            "Epoch 4/10, Train Loss: 0.2017, Val Loss: 0.2008\n",
            "Epoch 5/10, Train Loss: 0.1832, Val Loss: 0.1800\n",
            "Epoch 6/10, Train Loss: 0.1738, Val Loss: 0.1731\n",
            "Epoch 7/10, Train Loss: 0.1678, Val Loss: 0.1844\n",
            "Epoch 8/10, Train Loss: 0.1647, Val Loss: 0.1692\n",
            "Epoch 9/10, Train Loss: 0.1567, Val Loss: 0.1704\n",
            "Epoch 10/10, Train Loss: 0.1531, Val Loss: 0.1746\n",
            "================== TRAINING n_ahead = 7 ==================\n",
            "X_shape: (19556, 5, 20)\n",
            "y_shape: (19556, 7)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 7])\n",
            "Epoch 1/10, Train Loss: 0.4941, Val Loss: 0.3508\n",
            "Epoch 2/10, Train Loss: 0.3057, Val Loss: 0.3279\n",
            "Epoch 3/10, Train Loss: 0.2743, Val Loss: 0.3187\n",
            "Epoch 4/10, Train Loss: 0.2497, Val Loss: 0.2440\n",
            "Epoch 5/10, Train Loss: 0.2184, Val Loss: 0.2235\n",
            "Epoch 6/10, Train Loss: 0.2020, Val Loss: 0.2088\n",
            "Epoch 7/10, Train Loss: 0.1938, Val Loss: 0.2053\n",
            "Epoch 8/10, Train Loss: 0.1879, Val Loss: 0.2032\n",
            "Epoch 9/10, Train Loss: 0.1833, Val Loss: 0.2016\n",
            "Epoch 10/10, Train Loss: 0.1788, Val Loss: 0.2020\n",
            "================== TRAINING n_ahead = 8 ==================\n",
            "X_shape: (18567, 5, 20)\n",
            "y_shape: (18567, 8)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 8])\n",
            "Epoch 1/10, Train Loss: 0.5380, Val Loss: 0.4162\n",
            "Epoch 2/10, Train Loss: 0.3405, Val Loss: 0.3512\n",
            "Epoch 3/10, Train Loss: 0.3118, Val Loss: 0.3522\n",
            "Epoch 4/10, Train Loss: 0.2979, Val Loss: 0.3411\n",
            "Epoch 5/10, Train Loss: 0.2781, Val Loss: 0.3017\n",
            "Epoch 6/10, Train Loss: 0.2632, Val Loss: 0.2748\n",
            "Epoch 7/10, Train Loss: 0.2461, Val Loss: 0.2928\n",
            "Epoch 8/10, Train Loss: 0.2290, Val Loss: 0.2932\n",
            "Epoch 9/10, Train Loss: 0.2193, Val Loss: 0.2445\n",
            "Epoch 10/10, Train Loss: 0.2126, Val Loss: 0.2349\n",
            "================== TRAINING n_ahead = 9 ==================\n",
            "X_shape: (17598, 5, 20)\n",
            "y_shape: (17598, 9)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 9])\n",
            "Epoch 1/10, Train Loss: 0.5434, Val Loss: 0.4599\n",
            "Epoch 2/10, Train Loss: 0.3679, Val Loss: 0.3770\n",
            "Epoch 3/10, Train Loss: 0.3385, Val Loss: 0.3471\n",
            "Epoch 4/10, Train Loss: 0.3173, Val Loss: 0.3246\n",
            "Epoch 5/10, Train Loss: 0.3032, Val Loss: 0.3111\n",
            "Epoch 6/10, Train Loss: 0.2848, Val Loss: 0.3093\n",
            "Epoch 7/10, Train Loss: 0.2666, Val Loss: 0.2876\n",
            "Epoch 8/10, Train Loss: 0.2558, Val Loss: 0.2859\n",
            "Epoch 9/10, Train Loss: 0.2421, Val Loss: 0.2939\n",
            "Epoch 10/10, Train Loss: 0.2351, Val Loss: 0.2931\n",
            "================== TRAINING n_ahead = 10 ==================\n",
            "X_shape: (16663, 5, 20)\n",
            "y_shape: (16663, 10)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 10])\n",
            "Epoch 1/10, Train Loss: 0.6077, Val Loss: 0.5013\n",
            "Epoch 2/10, Train Loss: 0.4085, Val Loss: 0.4552\n",
            "Epoch 3/10, Train Loss: 0.3626, Val Loss: 0.4214\n",
            "Epoch 4/10, Train Loss: 0.3500, Val Loss: 0.4179\n",
            "Epoch 5/10, Train Loss: 0.3311, Val Loss: 0.3584\n",
            "Epoch 6/10, Train Loss: 0.3159, Val Loss: 0.3385\n",
            "Epoch 7/10, Train Loss: 0.2961, Val Loss: 0.3686\n",
            "Epoch 8/10, Train Loss: 0.2791, Val Loss: 0.3379\n",
            "Epoch 9/10, Train Loss: 0.2645, Val Loss: 0.3151\n",
            "Epoch 10/10, Train Loss: 0.2582, Val Loss: 0.3044\n",
            "================== TRAINING n_ahead = 11 ==================\n",
            "X_shape: (15757, 5, 20)\n",
            "y_shape: (15757, 11)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 11])\n",
            "Epoch 1/10, Train Loss: 0.6539, Val Loss: 0.4986\n",
            "Epoch 2/10, Train Loss: 0.4209, Val Loss: 0.4612\n",
            "Epoch 3/10, Train Loss: 0.3939, Val Loss: 0.4593\n",
            "Epoch 4/10, Train Loss: 0.3741, Val Loss: 0.4042\n",
            "Epoch 5/10, Train Loss: 0.3595, Val Loss: 0.4421\n",
            "Epoch 6/10, Train Loss: 0.3559, Val Loss: 0.3893\n",
            "Epoch 7/10, Train Loss: 0.3343, Val Loss: 0.3821\n",
            "Epoch 8/10, Train Loss: 0.3214, Val Loss: 0.3924\n",
            "Epoch 9/10, Train Loss: 0.3140, Val Loss: 0.3761\n",
            "Epoch 10/10, Train Loss: 0.2969, Val Loss: 0.3761\n",
            "================== TRAINING n_ahead = 12 ==================\n",
            "X_shape: (14881, 5, 20)\n",
            "y_shape: (14881, 12)\n",
            "batch_x shape: torch.Size([128, 5, 20])\n",
            "batch_y shape: torch.Size([128, 12])\n",
            "Epoch 1/10, Train Loss: 0.6649, Val Loss: 0.5898\n",
            "Epoch 2/10, Train Loss: 0.4440, Val Loss: 0.4807\n",
            "Epoch 3/10, Train Loss: 0.4098, Val Loss: 0.4576\n",
            "Epoch 4/10, Train Loss: 0.3901, Val Loss: 0.4482\n",
            "Epoch 5/10, Train Loss: 0.3783, Val Loss: 0.4632\n",
            "Epoch 6/10, Train Loss: 0.3699, Val Loss: 0.4129\n",
            "Epoch 7/10, Train Loss: 0.3542, Val Loss: 0.4101\n",
            "Epoch 8/10, Train Loss: 0.3445, Val Loss: 0.4655\n",
            "Epoch 9/10, Train Loss: 0.3304, Val Loss: 0.3949\n",
            "Epoch 10/10, Train Loss: 0.3199, Val Loss: 0.4086\n"
          ]
        }
      ],
      "source": [
        "#====================== Train model ======================#\n",
        "# config\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {torch.cuda.get_device_name(0)} for device\")\n",
        "\n",
        "# hyperparams\n",
        "in_features = (20, 50, 100)\n",
        "hidden_features = 100\n",
        "output_features = 1\n",
        "seq_len = 5\n",
        "n_aheads = list(range(1, 13))\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "num_workers = 0\n",
        "pin_memory = True\n",
        "\n",
        "results = {}\n",
        "\n",
        "for n_ahead in n_aheads:\n",
        "  print(f\"================== TRAINING n_ahead = {n_ahead} ==================\")\n",
        "  X_train, y_train, metadata_train = prepare_data(raw_train_data, sequence_length = 5, n_ahead = n_ahead)\n",
        "  X_val, y_val, metadata_val = prepare_data(raw_val_data, sequence_length = 5, n_ahead = n_ahead)\n",
        "  X_test, y_test, metadata_test = prepare_data(raw_test_data, sequence_length = 5, n_ahead = n_ahead)\n",
        "\n",
        "  print(f\"X_shape: {X_train.shape}\")\n",
        "  print(f\"y_shape: {y_train.shape}\")\n",
        "\n",
        "  raw_test_data_2020 = {k: v for k, v in raw_test_data.items() if int(k[-4:]) == 2020}\n",
        "  raw_test_data_2021 = {k: v for k, v in raw_test_data.items() if int(k[-4:]) == 2021}\n",
        "  raw_test_data_2022 = {k: v for k, v in raw_test_data.items() if int(k[-4:]) == 2022}\n",
        "\n",
        "  X_test_2020, y_test_2020, metadata_test_2020 = prepare_data(raw_test_data_2020, sequence_length = 5, n_ahead = n_ahead)\n",
        "  X_test_2021, y_test_2021, metadata_test_2021 = prepare_data(raw_test_data_2021, sequence_length = 5, n_ahead = n_ahead)\n",
        "  X_test_2022, y_test_2022, metadata_test_2022 = prepare_data(raw_test_data_2022, sequence_length = 5, n_ahead = n_ahead)\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  X_train_scaled = scaler_X.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
        "  X_val_scaled   = scaler_X.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)\n",
        "  X_test_scaled  = scaler_X.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
        "  X_test_2020_scaled = scaler_X.transform(X_test_2020.reshape(-1, X_test_2020.shape[-1])).reshape(X_test_2020.shape)\n",
        "  X_test_2021_scaled = scaler_X.transform(X_test_2021.reshape(-1, X_test_2021.shape[-1])).reshape(X_test_2021.shape)\n",
        "  X_test_2022_scaled = scaler_X.transform(X_test_2022.reshape(-1, X_test_2022.shape[-1])).reshape(X_test_2022.shape)\n",
        "\n",
        "  scaler_y = StandardScaler()\n",
        "  y_train_scaled = scaler_y.fit_transform(y_train)\n",
        "  y_val_scaled   = scaler_y.transform(y_val)\n",
        "  y_test_scaled  = scaler_y.transform(y_test)\n",
        "  y_test_2020_scaled = scaler_y.transform(y_test_2020)\n",
        "  y_test_2021_scaled = scaler_y.transform(y_test_2021)\n",
        "  y_test_2022_scaled = scaler_y.transform(y_test_2022)\n",
        "\n",
        "  train_dataset = StormDataset(X_train_scaled, y_train_scaled)\n",
        "  val_dataset = StormDataset(X_val_scaled, y_val_scaled)\n",
        "  test_dataset = StormDataset(X_test_scaled, y_test_scaled)\n",
        "  test_dataset_2020 = StormDataset(X_test_2020_scaled, y_test_2020_scaled)\n",
        "  test_dataset_2021 = StormDataset(X_test_2021_scaled, y_test_2021_scaled)\n",
        "  test_dataset_2022 = StormDataset(X_test_2022_scaled, y_test_2022_scaled)\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
        "  val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "  test_2020_loader = DataLoader(test_dataset_2020, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "  test_2021_loader = DataLoader(test_dataset_2021, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "  test_2022_loader = DataLoader(test_dataset_2022, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "\n",
        "  model = RNN_KAN(in_features, hidden_features, output_features, n_ahead)\n",
        "  model = model.to(device)\n",
        "  criterion = nn.MSELoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "  model, total_time, train_loss_per_epoch, val_loss_per_epoch = train_val(model, criterion, optimizer, train_loader, val_loader, device, batch_size, epochs)\n",
        "\n",
        "  test_mae = test(model, test_loader, scaler_y, device)\n",
        "  test_2020_mae = test(model, test_2020_loader, scaler_y, device)\n",
        "  test_2021_mae = test(model, test_2021_loader, scaler_y, device)\n",
        "  test_2022_mae = test(model, test_2022_loader, scaler_y, device)\n",
        "\n",
        "  results[n_ahead] = {\n",
        "      \"mae\": [test_mae, test_2020_mae, test_2021_mae, test_2022_mae],\n",
        "      \"time\": [total_time]\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6jVt9W4oUrZ",
        "outputId": "f9b454dd-3eb5-4955-de2a-baf94bde1cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction 6h: \n",
            "\t Total time: 43.06s\n",
            "\t Test MAE: 2.2912\n",
            "\t Test 2020 MAE: 1.6587\n",
            "\t Test 2021 MAE: 1.5704\n",
            "\t Test 2022 MAE: 3.9090\n",
            "Prediction 12h: \n",
            "\t Total time: 55.58s\n",
            "\t Test MAE: 2.8469\n",
            "\t Test 2020 MAE: 2.0908\n",
            "\t Test 2021 MAE: 2.0694\n",
            "\t Test 2022 MAE: 4.6908\n",
            "Prediction 18h: \n",
            "\t Total time: 53.81s\n",
            "\t Test MAE: 3.5166\n",
            "\t Test 2020 MAE: 2.5090\n",
            "\t Test 2021 MAE: 2.5497\n",
            "\t Test 2022 MAE: 5.9112\n",
            "Prediction 24h: \n",
            "\t Total time: 66.94s\n",
            "\t Test MAE: 4.2953\n",
            "\t Test 2020 MAE: 3.0632\n",
            "\t Test 2021 MAE: 2.8761\n",
            "\t Test 2022 MAE: 7.5970\n",
            "Prediction 30h: \n",
            "\t Total time: 134.02s\n",
            "\t Test MAE: 5.5395\n",
            "\t Test 2020 MAE: 3.6863\n",
            "\t Test 2021 MAE: 3.8055\n",
            "\t Test 2022 MAE: 10.0045\n",
            "Prediction 36h: \n",
            "\t Total time: 140.82s\n",
            "\t Test MAE: 5.6256\n",
            "\t Test 2020 MAE: 4.0229\n",
            "\t Test 2021 MAE: 3.7308\n",
            "\t Test 2022 MAE: 10.1154\n",
            "Prediction 42h: \n",
            "\t Total time: 146.26s\n",
            "\t Test MAE: 5.9525\n",
            "\t Test 2020 MAE: 4.3287\n",
            "\t Test 2021 MAE: 4.1533\n",
            "\t Test 2022 MAE: 10.4040\n",
            "Prediction 48h: \n",
            "\t Total time: 150.58s\n",
            "\t Test MAE: 5.9761\n",
            "\t Test 2020 MAE: 4.7251\n",
            "\t Test 2021 MAE: 4.5234\n",
            "\t Test 2022 MAE: 9.5649\n",
            "Prediction 54h: \n",
            "\t Total time: 153.68s\n",
            "\t Test MAE: 7.2265\n",
            "\t Test 2020 MAE: 5.2659\n",
            "\t Test 2021 MAE: 5.2133\n",
            "\t Test 2022 MAE: 12.5409\n",
            "Prediction 60h: \n",
            "\t Total time: 156.13s\n",
            "\t Test MAE: 6.7010\n",
            "\t Test 2020 MAE: 5.6061\n",
            "\t Test 2021 MAE: 4.9929\n",
            "\t Test 2022 MAE: 10.6345\n",
            "Prediction 66h: \n",
            "\t Total time: 157.42s\n",
            "\t Test MAE: 7.8945\n",
            "\t Test 2020 MAE: 6.2205\n",
            "\t Test 2021 MAE: 5.7014\n",
            "\t Test 2022 MAE: 13.2917\n",
            "Prediction 72h: \n",
            "\t Total time: 158.19s\n",
            "\t Test MAE: 7.6408\n",
            "\t Test 2020 MAE: 6.6140\n",
            "\t Test 2021 MAE: 5.7718\n",
            "\t Test 2022 MAE: 11.8408\n"
          ]
        }
      ],
      "source": [
        "for k,v in results.items():\n",
        "  print(f\"Prediction {k*6}h: \")\n",
        "  print(f\"\\t Total time: {v['time'][0]:.2f}s\")\n",
        "  print(f\"\\t Test MAE: {v['mae'][0]:.4f}\")\n",
        "  print(f\"\\t Test 2020 MAE: {v['mae'][1]:.4f}\")\n",
        "  print(f\"\\t Test 2021 MAE: {v['mae'][2]:.4f}\")\n",
        "  print(f\"\\t Test 2022 MAE: {v['mae'][3]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Short-term forecasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using NVIDIA GeForce RTX 4060 Ti for device\n",
            "================== TRAINING n_ahead = 3 ==================\n",
            "raw_electricity\n",
            "batch_x shape: torch.Size([32, 168, 321])\n",
            "batch_y shape: torch.Size([32, 3, 321])\n",
            "Epoch 1/10, Train Loss: 0.3164, Val Loss: 1.5371\n",
            "Epoch 2/10, Train Loss: 0.1788, Val Loss: 1.4956\n",
            "Epoch 3/10, Train Loss: 0.1516, Val Loss: 1.5054\n",
            "Epoch 4/10, Train Loss: 0.1374, Val Loss: 1.5164\n",
            "Epoch 5/10, Train Loss: 0.1289, Val Loss: 1.5003\n",
            "Epoch 6/10, Train Loss: 0.1225, Val Loss: 1.5313\n",
            "Epoch 7/10, Train Loss: 0.1173, Val Loss: 1.5154\n",
            "Epoch 8/10, Train Loss: 0.1131, Val Loss: 1.5133\n",
            "Epoch 9/10, Train Loss: 0.1100, Val Loss: 1.5054\n",
            "Epoch 10/10, Train Loss: 0.1075, Val Loss: 1.5337\n",
            "================== TRAINING n_ahead = 6 ==================\n",
            "raw_electricity\n",
            "batch_x shape: torch.Size([32, 168, 321])\n",
            "batch_y shape: torch.Size([32, 6, 321])\n",
            "Epoch 1/10, Train Loss: 0.3843, Val Loss: 1.7139\n",
            "Epoch 2/10, Train Loss: 0.2336, Val Loss: 1.7624\n",
            "Epoch 3/10, Train Loss: 0.1937, Val Loss: 1.7620\n",
            "Epoch 4/10, Train Loss: 0.1642, Val Loss: 1.7558\n",
            "Epoch 5/10, Train Loss: 0.1485, Val Loss: 1.8055\n",
            "Epoch 6/10, Train Loss: 0.1392, Val Loss: 1.7589\n",
            "Epoch 7/10, Train Loss: 0.1330, Val Loss: 1.7465\n",
            "Epoch 8/10, Train Loss: 0.1269, Val Loss: 1.7499\n",
            "Epoch 9/10, Train Loss: 0.1235, Val Loss: 1.7117\n",
            "Epoch 10/10, Train Loss: 0.1192, Val Loss: 1.7310\n",
            "================== TRAINING n_ahead = 12 ==================\n",
            "raw_electricity\n",
            "batch_x shape: torch.Size([32, 168, 321])\n",
            "batch_y shape: torch.Size([32, 12, 321])\n",
            "Epoch 1/10, Train Loss: 0.4458, Val Loss: 1.5601\n",
            "Epoch 2/10, Train Loss: 0.2938, Val Loss: 1.7132\n",
            "Epoch 3/10, Train Loss: 0.2463, Val Loss: 1.7326\n",
            "Epoch 4/10, Train Loss: 0.2262, Val Loss: 1.7137\n",
            "Epoch 5/10, Train Loss: 0.1964, Val Loss: 1.8057\n",
            "Epoch 6/10, Train Loss: 0.1822, Val Loss: 1.7922\n",
            "Epoch 7/10, Train Loss: 0.1748, Val Loss: 1.7752\n",
            "Epoch 8/10, Train Loss: 0.1585, Val Loss: 1.7316\n",
            "Epoch 9/10, Train Loss: 0.1492, Val Loss: 1.7671\n",
            "Epoch 10/10, Train Loss: 0.1425, Val Loss: 1.7716\n",
            "================== TRAINING n_ahead = 24 ==================\n",
            "raw_electricity\n",
            "batch_x shape: torch.Size([32, 168, 321])\n",
            "batch_y shape: torch.Size([32, 24, 321])\n",
            "Epoch 1/10, Train Loss: 0.4539, Val Loss: 1.6480\n",
            "Epoch 2/10, Train Loss: 0.3777, Val Loss: 1.6479\n",
            "Epoch 3/10, Train Loss: 0.3382, Val Loss: 1.6894\n",
            "Epoch 4/10, Train Loss: 0.2912, Val Loss: 1.5738\n",
            "Epoch 5/10, Train Loss: 0.2643, Val Loss: 1.6303\n",
            "Epoch 6/10, Train Loss: 0.2501, Val Loss: 1.5952\n",
            "Epoch 7/10, Train Loss: 0.2330, Val Loss: 1.6310\n",
            "Epoch 8/10, Train Loss: 0.2262, Val Loss: 1.5930\n",
            "Epoch 9/10, Train Loss: 0.2163, Val Loss: 1.6252\n",
            "Epoch 10/10, Train Loss: 0.2278, Val Loss: 1.6047\n",
            "================== TRAINING n_ahead = 3 ==================\n",
            "raw_exchange_rate\n",
            "batch_x shape: torch.Size([32, 168, 8])\n",
            "batch_y shape: torch.Size([32, 3, 8])\n",
            "Epoch 1/10, Train Loss: 0.3289, Val Loss: 2.3690\n",
            "Epoch 2/10, Train Loss: 0.1024, Val Loss: 2.2277\n",
            "Epoch 3/10, Train Loss: 0.0500, Val Loss: 2.1559\n",
            "Epoch 4/10, Train Loss: 0.0335, Val Loss: 2.1644\n",
            "Epoch 5/10, Train Loss: 0.0244, Val Loss: 2.0608\n",
            "Epoch 6/10, Train Loss: 0.0203, Val Loss: 2.0575\n",
            "Epoch 7/10, Train Loss: 0.0178, Val Loss: 2.0677\n",
            "Epoch 8/10, Train Loss: 0.0157, Val Loss: 2.0084\n",
            "Epoch 9/10, Train Loss: 0.0151, Val Loss: 2.0349\n",
            "Epoch 10/10, Train Loss: 0.0135, Val Loss: 2.0456\n",
            "================== TRAINING n_ahead = 6 ==================\n",
            "raw_exchange_rate\n",
            "batch_x shape: torch.Size([32, 168, 8])\n",
            "batch_y shape: torch.Size([32, 6, 8])\n",
            "Epoch 1/10, Train Loss: 0.4108, Val Loss: 3.2076\n",
            "Epoch 2/10, Train Loss: 0.1463, Val Loss: 2.8848\n",
            "Epoch 3/10, Train Loss: 0.0855, Val Loss: 2.7319\n",
            "Epoch 4/10, Train Loss: 0.0719, Val Loss: 3.1435\n",
            "Epoch 5/10, Train Loss: 0.0489, Val Loss: 3.1050\n",
            "Epoch 6/10, Train Loss: 0.0408, Val Loss: 3.2051\n",
            "Epoch 7/10, Train Loss: 0.0369, Val Loss: 3.0938\n",
            "Epoch 8/10, Train Loss: 0.0332, Val Loss: 3.0728\n",
            "Epoch 9/10, Train Loss: 0.0300, Val Loss: 3.0533\n",
            "Epoch 10/10, Train Loss: 0.0242, Val Loss: 3.0044\n",
            "================== TRAINING n_ahead = 12 ==================\n",
            "raw_exchange_rate\n",
            "batch_x shape: torch.Size([32, 168, 8])\n",
            "batch_y shape: torch.Size([32, 12, 8])\n",
            "Epoch 1/10, Train Loss: 0.4870, Val Loss: 3.6753\n",
            "Epoch 2/10, Train Loss: 0.2258, Val Loss: 3.7228\n",
            "Epoch 3/10, Train Loss: 0.1528, Val Loss: 3.9358\n",
            "Epoch 4/10, Train Loss: 0.1111, Val Loss: 3.7991\n",
            "Epoch 5/10, Train Loss: 0.0910, Val Loss: 3.9328\n",
            "Epoch 6/10, Train Loss: 0.0683, Val Loss: 3.7397\n",
            "Epoch 7/10, Train Loss: 0.0580, Val Loss: 3.8229\n",
            "Epoch 8/10, Train Loss: 0.0502, Val Loss: 3.9307\n",
            "Epoch 9/10, Train Loss: 0.0482, Val Loss: 3.8619\n",
            "Epoch 10/10, Train Loss: 0.0416, Val Loss: 3.7418\n",
            "================== TRAINING n_ahead = 24 ==================\n",
            "raw_exchange_rate\n",
            "batch_x shape: torch.Size([32, 168, 8])\n",
            "batch_y shape: torch.Size([32, 24, 8])\n",
            "Epoch 1/10, Train Loss: 0.6550, Val Loss: 3.8285\n",
            "Epoch 2/10, Train Loss: 0.3597, Val Loss: 3.6022\n",
            "Epoch 3/10, Train Loss: 0.2461, Val Loss: 4.2725\n",
            "Epoch 4/10, Train Loss: 0.2240, Val Loss: 4.1468\n",
            "Epoch 5/10, Train Loss: 0.1901, Val Loss: 4.0690\n",
            "Epoch 6/10, Train Loss: 0.1534, Val Loss: 4.4046\n",
            "Epoch 7/10, Train Loss: 0.1399, Val Loss: 4.2842\n",
            "Epoch 8/10, Train Loss: 0.1270, Val Loss: 4.1181\n",
            "Epoch 9/10, Train Loss: 0.1204, Val Loss: 4.0930\n",
            "Epoch 10/10, Train Loss: 0.1376, Val Loss: 4.2421\n"
          ]
        }
      ],
      "source": [
        "file_paths = [\n",
        "    # 'artifacts/raw_ETTh1-v0/raw_ETTh1.csv',\n",
        "    # 'artifacts/raw_ETTh2-v0/raw_ETTh2.csv',\n",
        "    # 'artifacts/raw_ETTm1-v0/raw_ETTm1.csv',\n",
        "    'artifacts/raw_electricity-v0/raw_electricity.csv',\n",
        "    'artifacts/raw_exchange_rate-v0/raw_exchange_rate.csv',\n",
        "    # 'artifacts/raw_PEMS03-v0/raw_PEMS03.pkl',\n",
        "    # 'artifacts/raw_PEMS04-v0/raw_PEMS04.pkl',\n",
        "    # 'artifacts/raw_PEMS07-v0/raw_PEMS07.pkl',\n",
        "    # 'artifacts/raw_PEMS08-v0/raw_PEMS08.pkl'\n",
        "]\n",
        "#====================== Train model ======================#\n",
        "# config\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {torch.cuda.get_device_name(0)} for device\")\n",
        "\n",
        "# hyperparams\n",
        "in_features = (20, 50, 100)\n",
        "hidden_features = 100\n",
        "\n",
        "window_size = 168\n",
        "n_aheads = [3, 6, 12, 24]\n",
        "epochs = 10\n",
        "num_workers = 0\n",
        "pin_memory = True\n",
        "\n",
        "results = {}\n",
        "for file_path in file_paths:\n",
        "  if file_path == 'artifacts/raw_electricity-v0/raw_electricity.csv':\n",
        "    batch_size = 32\n",
        "  if file_path == 'artifacts/raw_electricity-v0/raw_exchange_rate.csv':\n",
        "    batch_size = 4\n",
        "  for n_ahead in n_aheads:\n",
        "    print(f\"================== TRAINING n_ahead = {n_ahead} ==================\")\n",
        "    dm = DataModule(\n",
        "      file_path=file_path,\n",
        "    )\n",
        "\n",
        "    dm.setup()\n",
        "    dm.scale()\n",
        "    train_loader, val_loader, test_loader = dm.get_dataloader(batch_size=batch_size, window_size=window_size, horizon=n_ahead)\n",
        "    sample_x, sample_y = dm.train_dataset[0]\n",
        "\n",
        "    in_features = (sample_x.shape[-1], 50, 100)\n",
        "    out_features = sample_y.shape[-1]\n",
        "\n",
        "    model = RNN_KAN(in_features, hidden_features, out_features, n_ahead)\n",
        "    model = model.to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    model, total_time, train_loss_per_epoch, val_loss_per_epoch = train_val(model, criterion, optimizer, train_loader, val_loader, device, batch_size, epochs)\n",
        "\n",
        "    metrics = [nn.L1Loss()]\n",
        "    mae, mse = test(model, test_loader, dm, device)\n",
        "\n",
        "    results[n_ahead] = {\n",
        "        \"RSE\": mae,\n",
        "        \"CORR\": mse,\n",
        "        \"time\": [total_time]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{3: {'RSE': tensor(0.2462),\n",
              "  'CORR': tensor(-0.1243),\n",
              "  'time': [1218.8609449863434]},\n",
              " 6: {'RSE': tensor(0.3214), 'CORR': tensor(nan), 'time': [1266.7999322414398]},\n",
              " 12: {'RSE': tensor(0.3364),\n",
              "  'CORR': tensor(-0.0477),\n",
              "  'time': [1145.5743157863617]},\n",
              " 24: {'RSE': tensor(0.3430),\n",
              "  'CORR': tensor(-0.0155),\n",
              "  'time': [1950.2187852859497]}}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
